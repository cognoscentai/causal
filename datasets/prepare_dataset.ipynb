{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.integrate import odeint\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import sys, os\n",
    "sys.path.append(os.path.join(os.path.dirname(\"__file__\"), \"..\", \"..\"))\n",
    "from causal.util import plot_matrices, normalize_tensor\n",
    "from causal.pytorch_net.util import get_activation, to_Variable, to_np_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_time_series(time_series, K, K2 = 1, velocity_type = \"pos\", normalize = 0, is_cuda = False):\n",
    "    X = []\n",
    "    y = []\n",
    "    if normalize == 4:\n",
    "        num_time_series, length, N = time_series.shape\n",
    "        time_series = time_series.view(-1, N)\n",
    "        time_series = (time_series - time_series.mean(0, keepdim = True)) / time_series.std(0, keepdim = True)\n",
    "        time_series = time_series.view(num_time_series, length, N)\n",
    "    if velocity_type == \"both\":\n",
    "        for i in range(len(time_series)):\n",
    "            X_ele = []\n",
    "            y_ele = []\n",
    "            for k in range(1, time_series.size(1) - K - K2 + 1):\n",
    "                combined_X = torch.stack([time_series[i, k : k + K], time_series[i, k : k + K] - time_series[i, k - 1 : k + K - 1]], -1)\n",
    "                combined_X = combined_X.view(*combined_X.size()[:-2], -1)\n",
    "                combined_y = torch.stack([time_series[i, k + K : k + K + K2], time_series[i, k + K : k + K + K2] - time_series[i, k + K -1 : k + K + K2 - 1]], -1)\n",
    "                combined_y = combined_y.view(*combined_y.size()[:-2], -1)\n",
    "                X_ele.append(combined_X)\n",
    "                y_ele.append(combined_y)\n",
    "            X.append(torch.stack(X_ele))\n",
    "            y.append(torch.stack(y_ele))\n",
    "    elif velocity_type == \"pos\":\n",
    "        for i in range(len(time_series)):\n",
    "            X_ele = []\n",
    "            y_ele = []\n",
    "            for k in range(1, time_series.size(1) - K - K2 + 1):\n",
    "                X_ele.append(time_series[i, k : k + K])\n",
    "                y_ele.append(time_series[i, k + K : k + K + K2])\n",
    "            X.append(torch.stack(X_ele))\n",
    "            y.append(torch.stack(y_ele))\n",
    "    elif velocity_type == \"velocity\":\n",
    "        for i in range(len(time_series)):\n",
    "            X_ele = []\n",
    "            y_ele = []\n",
    "            for k in range(1, time_series.size(1) - K - K2 + 1):\n",
    "                X_ele.append(time_series[i, k : k + K] - time_series[i, k - 1 : k + K - 1])\n",
    "                y_ele.append(time_series[i, k + K : k + K + K2] - time_series[i, k + K -1 : k + K + K2 - 1])\n",
    "            X.append(torch.stack(X_ele))\n",
    "            y.append(torch.stack(y_ele))\n",
    "    else:\n",
    "        raise\n",
    "    X = torch.stack(X)\n",
    "    y = torch.stack(y)\n",
    "    X, y = normalize_tensor(X, y, normalize = normalize)\n",
    "    if is_cuda:\n",
    "        X = X.cuda()\n",
    "        y = y.cuda()\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def get_A_matrix(N, K, p_N = 0.5, p_K = 0.5, dist_type = \"uniform\", isTorch = True, is_cuda = False, isplot = False):\n",
    "    on_series = np.random.choice([0, 1], size = N, p = [1-p_N, p_N])\n",
    "    A = np.zeros((K, N))\n",
    "    for j, element in enumerate(on_series):\n",
    "        if element == 1:\n",
    "            if dist_type == \"uniform\":\n",
    "                A[:, j] = (np.random.randn(K) * 0.1 + 0.4) * np.random.choice([1,-1], size = K) * np.random.choice([0, 1], size = K, p = [1-p_K, p_K])\n",
    "            elif dist_type == \"lognormal\":\n",
    "                A[:, j] = np.random.lognormal(size = K) * np.random.choice([1,-1], size = K) * np.random.choice([0, 1], size = K, p = [1-p_K, p_K])\n",
    "            elif dist_type == \"exponential\":\n",
    "                A[:, j] = np.random.exponential(size = K) * np.random.choice([1,-1], size = K) * np.random.choice([0, 1], size = K, p = [1-p_K, p_K])\n",
    "            else:\n",
    "                raise Exception(\"dist_type {0} not valid!\".format(dist_type))\n",
    "    if isplot:\n",
    "        plot_matrices([np.abs(A)])\n",
    "    if isTorch:\n",
    "        A = torch.Tensor(A)\n",
    "        if is_cuda:\n",
    "            A = A.cuda()\n",
    "    return A\n",
    "\n",
    "\n",
    "def get_synthetic_data(\n",
    "    N,\n",
    "    K,\n",
    "    K2 = 1,\n",
    "    p_N = 0.5,\n",
    "    p_K = 0.5,\n",
    "    time_length = 10,\n",
    "    num_examples = 3000,\n",
    "    A_whole = None,\n",
    "    dist_type = \"uniform\",\n",
    "    mode = \"linear\",\n",
    "    indi_activation = None,\n",
    "    noise_multiplicative_matrix = None,\n",
    "    noise_variance = None,\n",
    "    observational_model = None,\n",
    "    isplot = False,\n",
    "    velocity_type = \"pos\",\n",
    "    normalize = 0,\n",
    "    is_cuda = False,\n",
    "    ):\n",
    "    # Configure causal factor A:\n",
    "    if A_whole is None:\n",
    "        A_whole = np.zeros((N, K, N))\n",
    "        for n in range(N):\n",
    "            A_whole[n] = get_A_matrix(N, K, p_N = p_N, p_K = p_K, dist_type = dist_type, isTorch = False)\n",
    "    else:\n",
    "        assert A_whole.shape[0] == A_whole.shape[2], \"A_whole must have the shape of (N, K, N)!\"\n",
    "    if isplot:\n",
    "        plot_matrices(A_whole)\n",
    "\n",
    "    # Configure individual scaling factor B:\n",
    "    if indi_activation is not None:\n",
    "        B_whole = np.random.choice([1,-1], size = (N, K, N)) * (np.random.rand(N, K, N) + 1)\n",
    "    else:\n",
    "        B_whole = None\n",
    "\n",
    "    # configure noise_multiplicative_matrix\n",
    "    if noise_multiplicative_matrix is not None:\n",
    "        if isinstance(noise_multiplicative_matrix, str) and noise_multiplicative_matrix == \"random\":\n",
    "            noise_multiplicative_matrix = torch.zeros(N, K, N)\n",
    "            for n in range(N):\n",
    "                noise_multiplicative_matrix[n] = get_A_matrix(N, K, p_N = p_N, p_K = p_K, dist_type = dist_type, isTorch = True).abs()\n",
    "        else:\n",
    "            noise_multiplicative_matrix = to_Variable(noise_multiplicative_matrix).abs()\n",
    "            shape = noise_multiplicative_matrix.shape\n",
    "            if len(shape) == 2:\n",
    "                assert shape[0] == shape[1]\n",
    "                noise_multiplicative_matrix = noise_multiplicative_matrix.unsqueeze(1).repeat(1, K, 1)\n",
    "        if isplot:\n",
    "            print(\"noise_multiplicative_matrix:\")\n",
    "            plot_matrices(to_np_array(noise_multiplicative_matrix))\n",
    "\n",
    "    # Begin time-series generation:\n",
    "    time_series_all = []\n",
    "    for i in range(int(num_examples / time_length)):\n",
    "        x = torch.randn(K, N)\n",
    "        time_series = [x]\n",
    "        for j in range(time_length):\n",
    "            if noise_variance is not None:\n",
    "                if isinstance(noise_variance, np.ndarray) or isinstance(noise_variance, list):\n",
    "                    noise_to_add = np.random.multivariate_normal(np.zeros(N), noise_variance, size = time_length)\n",
    "                else:\n",
    "                    noise_to_add = np.random.randn(time_length, N) * np.sqrt(noise_variance)\n",
    "            x_t = torch.zeros(1, N)\n",
    "            for n in range(N):\n",
    "                if indi_activation is not None:\n",
    "                    x_core = get_activation(indi_activation)(torch.FloatTensor(B_whole[n]) * x)\n",
    "                else:\n",
    "                    x_core = x\n",
    "                if noise_multiplicative_matrix is None:\n",
    "                    x_t[0, n] = get_activation(mode)((torch.FloatTensor(A_whole[n]) * x_core).sum())\n",
    "                else:\n",
    "                    x_t[0, n] = get_activation(mode)((torch.FloatTensor(A_whole[n]) * noise_multiplicative_matrix[n] * torch.randn(K, N) * x_core + \n",
    "                                                      torch.FloatTensor(A_whole[n]) * (noise_multiplicative_matrix[n] < 1e-9).float() * x_core).sum())\n",
    "                if noise_variance is not None:\n",
    "                    x_t[0, n] += noise_to_add[j, n]\n",
    "            time_series.append(x_t)\n",
    "            x = torch.cat([x[1:], x_t], 0)\n",
    "        time_series = torch.cat(time_series, 0)\n",
    "        time_series_all.append(time_series)\n",
    "\n",
    "    time_series_all = torch.stack(time_series_all)\n",
    "\n",
    "    if isplot:\n",
    "        for kk in range(4):\n",
    "            plt.figure(figsize = (20, 8))\n",
    "            plt.plot(time_series_all[kk].numpy())\n",
    "            plt.legend(list(range(time_series_all.size(-1))))\n",
    "\n",
    "    # Apply observational model if given:\n",
    "    if observational_model is not None:\n",
    "        if isinstance(observational_model, list):\n",
    "            shape = time_series_all.shape\n",
    "            time_series_all_new = []\n",
    "            for i, model in enumerate(observational_model):\n",
    "                time_series = model(time_series_all[...,i:i+1].contiguous().view(-1, 1))\n",
    "                time_series_all_new.append(time_series)\n",
    "            time_series_all = torch.cat(time_series_all_new, -1).view(shape[0], shape[1], -1)\n",
    "        else:\n",
    "            time_series_all = observational_model(time_series_all)\n",
    "        time_series_all = to_Variable(time_series_all, requires_grad = False)\n",
    "\n",
    "    X, y = process_time_series(time_series_all, K = K, K2 = K2, velocity_type = velocity_type, normalize = normalize, is_cuda = is_cuda)\n",
    "    if is_cuda:\n",
    "        time_series_all = time_series_all.cuda()\n",
    "    return (X, y), A_whole, B_whole, time_series_all"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
